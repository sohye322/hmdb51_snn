{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1586,"status":"ok","timestamp":1741685784442,"user":{"displayName":"양소혜","userId":"09611961107409321329"},"user_tz":-540},"id":"B8ax4ntScd3I","outputId":"af143982-50b9-4d73-9b27-76b05a6def20"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')\n","os.listdir(\"/content/drive/MyDrive\")\n","os.chdir(\"/content/drive/MyDrive/hmdb51\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2414,"status":"ok","timestamp":1741685786859,"user":{"displayName":"양소혜","userId":"09611961107409321329"},"user_tz":-540},"id":"UYkxwDfNNxwU","outputId":"0ad6ea3e-5810-456b-87ea-a3f021814921"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spikingjelly in /usr/local/lib/python3.11/dist-packages (0.0.0.0.14)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from spikingjelly) (2.5.1+cu124)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from spikingjelly) (3.10.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from spikingjelly) (1.26.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from spikingjelly) (4.67.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from spikingjelly) (0.20.1+cu124)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from spikingjelly) (1.13.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (2.8.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (12.3.1.170)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (12.4.127)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->spikingjelly) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->spikingjelly) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->spikingjelly) (3.0.2)\n"]}],"source":["!pip install spikingjelly"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2420,"status":"ok","timestamp":1741685789294,"user":{"displayName":"양소혜","userId":"09611961107409321329"},"user_tz":-540},"id":"vHiHxvrjdhVt","outputId":"aba3d36d-225b-45db-dd13-e3c4847d476b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: av in /usr/local/lib/python3.11/dist-packages (14.2.0)\n"]}],"source":["! pip install av\n","#! wget https://raw.githubusercontent.com/pytorch/vision/6de158c473b83cf43344a0651d7c01128c7850e6/references/video_classification/transforms.py"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4005,"status":"ok","timestamp":1741685793344,"user":{"displayName":"양소혜","userId":"09611961107409321329"},"user_tz":-540},"id":"JyL3cg9qadrZ"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch.utils.data import random_split, DataLoader\n","from torch.optim.lr_scheduler import StepLR\n","import torchvision\n","from torchvision import get_video_backend\n","from torchvision.models.video import r3d_18\n","from torchvision import transforms\n","import os\n","import av\n","from tqdm.auto import tqdm\n","import numpy as np\n","import time\n","import datetime\n","import random\n","import transforms as T\n","import matplotlib.pyplot as plt\n","\n","\n","from spikingjelly.activation_based import layer, neuron, surrogate, encoding, functional"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1741685793462,"user":{"displayName":"양소혜","userId":"09611961107409321329"},"user_tz":-540},"id":"8LOk8nvOecsw"},"outputs":[],"source":["class HMDB51CSNN(nn.Module):\n","  def __init__(self, channels=128):\n","    super().__init__()\n","\n","    conv = []\n","    for i in range (5):\n","      if conv.__len__() == 0:\n","        in_channels = 3\n","      else:\n","        in_channels = channels\n","\n","      conv.append(layer.Conv2d(in_channels, channels, kernel_size=3, padding=1, bias=False))\n","      conv.append(layer.BatchNorm2d(channels))\n","      conv.append(neuron.IFNode(surrogate_function=surrogate.ATan()))\n","      conv.append(layer.MaxPool2d(2,2)) # 112->56->28->14->7->3\n","\n","    self.conv_fc = nn.Sequential(\n","        *conv,\n","\n","        layer.Flatten(),\n","        layer.Dropout(0.5),\n","        layer.Linear(channels * 3 * 3, 512),\n","\n","        layer.Dropout(0.5),\n","        layer.Linear(512, 510),\n","        neuron.IFNode(surrogate_function=surrogate.ATan()),\n","\n","        layer.VotingLayer(10)\n","    )\n","\n","    functional.set_step_mode(self, step_mode='m')\n","\n","  def forward(self, x: torch.Tensor):\n","    return self.conv_fc(x)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"elapsed":11573,"status":"error","timestamp":1741685392332,"user":{"displayName":"양소혜","userId":"09611961107409321329"},"user_tz":-540},"id":"p2PqVIRpamQF","outputId":"93f2cb72-fc60-4b43-cd72-abba900dc474"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-715088aaa510>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                                              \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCenterCrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m112\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m112\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                              ])\n\u001b[0;32m---> 21\u001b[0;31m hmdb51_train = torchvision.datasets.HMDB51('video_data/', 'test_train_splits/', num_frames,\n\u001b[0m\u001b[1;32m     22\u001b[0m                                                 \u001b[0mstep_between_clips\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                                 transform=train_tfms, num_workers=num_workers)\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/hmdb51.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, annotation_path, frames_per_clip, step_between_clips, frame_rate, fold, train, transform, _precomputed_metadata, num_workers, _video_width, _video_height, _video_min_dimension, _audio_samples, output_format)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mextensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"avi\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         self.samples = make_dataset(\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfnames\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/os.py\u001b[0m in \u001b[0;36m_walk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Datasets and Dataloaders for model training ..\n","\n","val_split = 0.05\n","num_frames = 20\n","clip_steps = 50\n","num_workers = 8\n","pin_memory = True\n","train_tfms = torchvision.transforms.Compose([\n","                                 T.ToFloatTensorInZeroOne(),\n","                                 T.Resize((128, 171)),\n","                                 T.RandomHorizontalFlip(),\n","                                 T.Normalize(mean=[0.43216, 0.394666, 0.37645], std=[0.22803, 0.22145, 0.216989]),\n","                                 T.RandomCrop((112, 112))\n","                               ])\n","test_tfms =  torchvision.transforms.Compose([\n","                                             T.ToFloatTensorInZeroOne(),\n","                                             T.Resize((128, 171)),\n","                                             T.Normalize(mean=[0.43216, 0.394666, 0.37645], std=[0.22803, 0.22145, 0.216989]),\n","                                             T.CenterCrop((112, 112))\n","                                             ])\n","hmdb51_train = torchvision.datasets.HMDB51('video_data/', 'test_train_splits/', num_frames,\n","                                                step_between_clips = clip_steps, fold=1, train=True,\n","                                                transform=train_tfms, num_workers=num_workers)\n","\n","\n","hmdb51_test = torchvision.datasets.HMDB51('video_data/', 'test_train_splits/', num_frames,\n","                                                step_between_clips = clip_steps, fold=1, train=False,\n","                                                transform=test_tfms, num_workers=num_workers)\n","\n","total_train_samples = len(hmdb51_train)\n","total_val_samples = round(val_split * total_train_samples)\n","\n","print(f\"number of train samples {total_train_samples}\")\n","print(f\"number of validation samples {total_val_samples}\")\n","print(f\"number of test samples {len(hmdb51_test)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0CJ-oy55fuTS"},"outputs":[],"source":["batch_size = 32\n","num_workers = 0\n","\n","kwargs = {'num_workers':num_workers, 'pin_memory':True} if torch.cuda.is_available() else {'num_workers':num_workers}\n","#kwargs = {'num_workers':num_workers}\n","#kwargs = {}\n","\n","hmdb51_train_v1, hmdb51_val_v1 = random_split(hmdb51_train, [total_train_samples - total_val_samples,\n","                                                                       total_val_samples])\n","\n","#hmdb51_train_v1.video_clips.compute_clips(16, 1, frame_rate=30)\n","#hmdb51_val_v1.video_clips.compute_clips(16, 1, frame_rate=30)\n","#hmdb51_test.video_clips.compute_clips(16, 1, frame_rate=30)\n","\n","#train_sampler = RandomClipSampler(hmdb51_train_v1.video_clips, 5)\n","#test_sampler = UniformClipSampler(hmdb51_test.video_clips, 5)\n","\n","train_loader = DataLoader(hmdb51_train_v1, batch_size=batch_size, shuffle=True, **kwargs)\n","val_loader   = DataLoader(hmdb51_val_v1, batch_size=batch_size, shuffle=True, **kwargs)\n","test_loader  = DataLoader(hmdb51_test, batch_size=batch_size, shuffle=False, **kwargs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2850,"status":"ok","timestamp":1741612975099,"user":{"displayName":"양소혜","userId":"09611961107409321329"},"user_tz":-540},"id":"vLjJp-CK2ry9","outputId":"66b480ea-a1ac-4af0-f05c-1b50c4780b6a"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torchvision/io/video.py:169: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"]},{"name":"stdout","output_type":"stream","text":["Batch type: <class 'list'>\n","Batch length: 3\n","torch.Size([32, 3, 20, 112, 112])\n","torch.Size([32, 1, 0])\n","torch.Size([32])\n"]}],"source":["batch = next(iter(train_loader))\n","print(f\"Batch type: {type(batch)}\")\n","print(f\"Batch length: {len(batch)}\")\n","\n","video, audio, label = next(iter(train_loader))\n","print(video.shape) # (batch size, channels, frames, height, width)\n","print(audio.shape)\n","print(label.shape) # (batch size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":278,"status":"ok","timestamp":1741612975381,"user":{"displayName":"양소혜","userId":"09611961107409321329"},"user_tz":-540},"id":"tJtUn5Bu06MT","outputId":"8839298f-585c-4f86-eb1c-da05e2f4c78d"},"outputs":[{"data":{"text/plain":["['hmdb51_test.pkl']"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["import joblib\n","\n","joblib.dump(train_loader, \"hmdb51_train.pkl\")\n","joblib.dump(test_loader, \"hmdb51_test.pkl\")"]},{"cell_type":"markdown","metadata":{"id":"nBSMWf_Z1hyN"},"source":["아래 코드로 train_loader, test_loader 바로 가져오기"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":590,"status":"ok","timestamp":1741685795352,"user":{"displayName":"양소혜","userId":"09611961107409321329"},"user_tz":-540},"id":"lKeyvOZj1oiL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"273d2b91-e196-4b78-c1e5-fceedcf82dc8"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/datasets/video_utils.py:219: UserWarning: There aren't enough frames in the current video to get a clip for the given clip length and frames between clips. The video (and potentially others) will be skipped.\n","  warnings.warn(\n"]}],"source":["import joblib\n","\n","train_loader = joblib.load(\"hmdb51_train.pkl\")\n","test_loader = joblib.load(\"hmdb51_test.pkl\")"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1741685576118,"user":{"displayName":"양소혜","userId":"09611961107409321329"},"user_tz":-540},"id":"tG9hb2Ctdm7r","outputId":"86b3dad6-0767-49c2-de81-f641aa3ab3bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["train_loader의 총 sample 개수: 7059\n","test_loader의 총 sample 개수: 3101\n","batch 당 sample 수 (batch size): 32\n"]}],"source":["print(f\"train_loader의 총 sample 개수: {len(train_loader.dataset)}\")\n","print(f\"test_loader의 총 sample 개수: {len(test_loader.dataset)}\")\n","print(f\"batch 당 sample 수 (batch size): {train_loader.batch_size}\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":298,"status":"ok","timestamp":1741685798568,"user":{"displayName":"양소혜","userId":"09611961107409321329"},"user_tz":-540},"id":"HS-55-V68-TK","outputId":"ada77816-d6b4-4371-b890-7ebd2869ab47"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-7-7104a737a79c>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = torch.cuda.amp.GradScaler()\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","lr = 0.001\n","gamma = 0.7\n","epochs = 30\n","config = {}\n","net = HMDB51CSNN().to(device)\n","optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n","encoder = encoding.PoissonEncoder()\n","scaler = torch.cuda.amp.GradScaler()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607},"id":"tV9vZLbs7w7e","executionInfo":{"status":"error","timestamp":1741685830412,"user_tz":-540,"elapsed":30813,"user":{"displayName":"양소혜","userId":"09611961107409321329"}},"outputId":"0ad6669a-e252-4a53-8063-a3b8cebe8dea"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-8-10cb5194580c>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(checkpoint_path)\n"]},{"output_type":"stream","name":"stdout","text":["체크포인트 불러옴: epoch 10, max_test_acc=13.83%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/io/video.py:169: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\nRuntimeError: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\nRuntimeError: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 56.12 MiB is free. Process 104767 has 14.68 GiB memory in use. Of the allocated memory 14.55 GiB is allocated by PyTorch, and 15.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-10cb5194580c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mlabel_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m51\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mout_fr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_fr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-7c16df40c9f3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spikingjelly/activation_based/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_step_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'm'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_step_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spikingjelly/activation_based/neuron.py\u001b[0m in \u001b[0;36mmulti_step_forward\u001b[0;34m(self, x_seq)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'torch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_step_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cupy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                 \u001b[0mhard_reset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_reset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spikingjelly/activation_based/neuron.py\u001b[0m in \u001b[0;36mmulti_step_forward\u001b[0;34m(self, x_seq)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mv_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_step_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m             \u001b[0my_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_v_seq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spikingjelly/activation_based/neuron.py\u001b[0m in \u001b[0;36msingle_step_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msingle_step_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_step_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_float_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spikingjelly/activation_based/neuron.py\u001b[0m in \u001b[0;36msingle_step_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneuronal_charge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mspike\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneuronal_fire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneuronal_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mspike\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spikingjelly/activation_based/neuron.py\u001b[0m in \u001b[0;36mneuronal_reset\u001b[0;34m(self, spike)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;31m# hard reset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit_hard_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspike_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_reset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\nRuntimeError: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\nRuntimeError: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 56.12 MiB is free. Process 104767 has 14.68 GiB memory in use. Of the allocated memory 14.55 GiB is allocated by PyTorch, and 15.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n"]}],"source":["checkpoint_path = \"/content/drive/MyDrive/commit/graduate/hmdb51csnn_checkpoint.pth\"\n","start_epoch = 0\n","max_test_acc = -1\n","train_losses = []\n","train_accs = []\n","test_losses = []\n","test_accs = []\n","\n","# check point 불러오기\n","if os.path.exists(checkpoint_path):\n","    checkpoint = torch.load(checkpoint_path)\n","    net.load_state_dict(checkpoint[\"model_state\"])\n","    optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n","    start_epoch = checkpoint[\"epoch\"]\n","    max_test_acc = checkpoint[\"max_test_acc\"]\n","    train_losses = checkpoint.get(\"train_losses\", [])\n","    train_accs = checkpoint.get(\"train_accs\", [])\n","    test_losses = checkpoint.get(\"test_losses\", [])\n","    test_accs = checkpoint.get(\"test_accs\", [])\n","    print(f\"체크포인트 불러옴: epoch {start_epoch}, max_test_acc={max_test_acc*100:.2f}%\")\n","else:\n","    print(\"새로운 학습을 시작합니다.\")\n","\n","# train & test\n","for epoch in range(start_epoch, epochs):\n","    start_time = time.time()\n","    net.train()\n","    train_loss = 0\n","    train_acc = 0\n","    train_samples = 0\n","\n","    for batch_idx, (frame, _, label) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        frame = frame.to(device)\n","        frame = frame.permute(2,0,1,3,4) # [N,T,C,H,W] -> [T,N,C,H,W]\n","        label = label.to(device)\n","        label_onehot = F.one_hot(label,  51).float()\n","\n","        out_fr = net(frame).mean(0)\n","        loss = F.mse_loss(out_fr, label_onehot)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_samples += label.numel()\n","        train_loss += loss.item() * label.numel()\n","        train_acc += (out_fr.argmax(1) == label).float().sum().item()\n","\n","        functional.reset_net(net)\n","\n","    train_time = time.time()\n","    train_speed = train_samples / (train_time - start_time)\n","    train_loss /= train_samples\n","    train_acc /= train_samples\n","    print(f'epoch {epoch}: train_loss={train_loss*100:.2f}%, train_acc={train_acc*100:.2f}%, train_speed={train_speed:.4f}images/s')\n","\n","    net.eval()\n","    test_loss = 0\n","    test_acc = 0\n","    test_samples = 0\n","    with torch.no_grad():\n","        for frame, _, label in test_loader:\n","            frame = frame.to(device)\n","            frame = frame.permute(2,0,1,3,4)  # [N, T, C, H, W] -> [T, N, C, H, W]\n","            label = label.to(device)\n","            label_onehot = F.one_hot(label, 51).float()\n","            out_fr = net(frame).mean(0)\n","            loss = F.mse_loss(out_fr, label_onehot)\n","            test_samples += label.numel()\n","            test_loss += loss.item() * label.numel()\n","            test_acc += (out_fr.argmax(1) == label).float().sum().item()\n","            functional.reset_net(net)\n","\n","    test_time = time.time()\n","    test_speed = test_samples / (test_time - train_time)\n","    test_loss /= test_samples\n","    test_acc /= test_samples\n","\n","    if test_acc > max_test_acc:\n","        max_test_acc = test_acc\n","\n","    print(f'epoch = {epoch}, test_loss={test_loss*100:.2f}%, test_acc={test_acc*100:.2f}%, max_test_acc={max_test_acc*100:.2f}%, test_speed={test_speed:.4f}images/s')\n","    print(f'escape time = {(datetime.datetime.now() + datetime.timedelta(seconds=(time.time() - start_time) * (epochs - epoch))).strftime(\"%Y-%m-%d %H:%M:%S\")}\\n')\n","\n","    train_losses.append(train_loss)\n","    train_accs.append(train_acc)\n","    test_losses.append(test_loss)\n","    test_accs.append(test_acc)\n","\n","    checkpoint = {\n","        \"epoch\": epoch + 1,  # 다음 epoch부터 학습을 이어가므로 1 증가\n","        \"model_state\": net.cpu().state_dict(),\n","        \"optimizer_state\": optimizer.state_dict(),\n","        \"max_test_acc\": max_test_acc,\n","        \"train_losses\": train_losses,\n","        \"train_accs\": train_accs,\n","        \"test_losses\": test_losses,\n","        \"test_accs\": test_accs\n","    }\n","    torch.save(checkpoint, checkpoint_path)\n","    net.to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PJqbMd8zG_mu"},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6LrfRjOSGzeW"},"outputs":[],"source":["checkpoint_path = \"/content/drive/MyDrive/commit/graduate/hmdb51csnn_checkpoint.pth\"\n","checkpoint = torch.load(checkpoint_path)\n","\n","# 저장된 데이터 가져오기\n","epochs = checkpoint[\"epoch\"]  # 저장된 마지막 epoch\n","max_test_acc = checkpoint[\"max_test_acc\"]  # 최고 테스트 정확도\n","train_losses = checkpoint.get(\"train_losses\", [])  # 학습 손실\n","test_losses = checkpoint.get(\"test_losses\", [])  # 테스트 손실\n","test_accs = checkpoint.get(\"test_accs\", [])  # 테스트 정확도\n","\n","# epoch 리스트 생성\n","epoch_list = list(range(1, epochs + 1))\n","\n","# 그래프 크기 설정\n","plt.figure(figsize=(12, 5))\n","\n","# Loss 그래프\n","plt.subplot(1, 2, 1)\n","plt.plot(epoch_list, train_losses, label=\"Train Loss\", marker=\"o\")\n","plt.plot(epoch_list, test_losses, label=\"Test Loss\", marker=\"o\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Epoch vs Loss\")\n","plt.legend()\n","plt.grid()\n","\n","# Accuracy 그래프\n","plt.subplot(1, 2, 2)\n","plt.plot(epoch_list, test_accs, label=\"Test Accuracy\", marker=\"o\", color=\"r\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Accuracy\")\n","plt.title(\"Epoch vs Accuracy\")\n","plt.legend()\n","plt.grid()\n","\n","# 그래프 출력\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}